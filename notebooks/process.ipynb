{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff28c98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp zbook\\Documents\\GitHub\\Geasture_ESP\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02d64baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Timestamp  Accel X  Accel Y  Accel Z  Gyro X  Gyro Y  Gyro Z     lable\n",
      "0      14:49:24     2.36    -8.24    -3.47   -0.01    0.30   -0.16      down\n",
      "1      14:49:24     3.21    -9.22    -2.42    0.11   -0.41    0.22      down\n",
      "2      14:49:24     1.83   -10.16    -2.82    0.13    0.00   -0.02      down\n",
      "3      14:49:24     2.58    -9.41    -2.58   -0.04    0.32   -0.16      down\n",
      "4      14:49:24     3.34    -8.63    -2.44   -0.17    0.20   -0.05      down\n",
      "...         ...      ...      ...      ...     ...     ...     ...       ...\n",
      "13728  19:11:07    -0.71    -0.69     8.65    0.00   -0.04    0.01  striaght\n",
      "13729  19:11:07    -0.69    -0.73     8.68    0.02   -0.01    0.01  striaght\n",
      "13730  19:11:08    -0.69    -0.69     8.63    0.00   -0.05    0.01  striaght\n",
      "13731  19:11:08    -0.60    -0.71     8.66    0.00   -0.03    0.01  striaght\n",
      "13732  19:11:08    -0.84    -0.67     8.61    0.01    0.01    0.01  striaght\n",
      "\n",
      "[13733 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your Excel file\n",
    "data = pd.read_excel(r\"data\\sensor_data.xlsx\")\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5498f8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean column names\n",
    "data.columns = data.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "# Drop missing values\n",
    "data_cleaned = data.dropna()\n",
    "\n",
    "# Define numerical features\n",
    "features = ['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z']\n",
    "\n",
    "# IQR outlier removal\n",
    "def remove_outliers(df, features):\n",
    "    Q1 = df[features].quantile(0.25)\n",
    "    Q3 = df[features].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    mask = ~((df[features] < (Q1 - 1.5 * IQR)) | (df[features] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "    return df[mask]\n",
    "\n",
    "\n",
    "# Apply for each movement\n",
    "filtered_data = pd.concat([\n",
    "    remove_outliers(data_cleaned[data_cleaned['lable'] == label], features)\n",
    "    for label in data_cleaned['lable'].unique()\n",
    "])\n",
    "for label in filtered_data['lable'].unique():\n",
    "    subset = filtered_data[filtered_data['lable'] == label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "041a9999",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Extract features and labels\n",
    "features = ['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z']\n",
    "X_raw = filtered_data[features]\n",
    "y_raw = filtered_data['lable']\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_raw)\n",
    "\n",
    "# Recreate the DataFrame with labels\n",
    "normalized_data = pd.DataFrame(X_scaled, columns=features)\n",
    "normalized_data['label'] = y_raw.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ab49ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function\n",
    "X_seq, y_seq = create_sequences(normalized_data, features)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y_seq)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b1428a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data saved to 'preprocessed_sensor_data.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save the normalized data to a new CSV file\n",
    "normalized_data.to_csv(r\"data\\preprocessed_sensor_data.csv\", index=False)\n",
    "print(\"Preprocessed data saved to 'preprocessed_sensor_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bf65564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/scaler.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(scaler, \"models/scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33830d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grad_ESP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
